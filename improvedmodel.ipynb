{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa30e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import os, gc, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timezone\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "\n",
    "# Basic config - edit paths\n",
    "RAW_CSV = \"E:/DL Project/data/lob.csv\"   # change to your original file path\n",
    "CLEAN_CSV = \"E:/DL Project/data/cleaned.csv\"  # where cleaned file will be saved\n",
    "os.makedirs(os.path.dirname(CLEAN_CSV), exist_ok=True)\n",
    "\n",
    "# Parameters you may want to tune\n",
    "WINDOW_SIZE = 300   # deepLOB default\n",
    "HORIZON = 1         # label horizon (how many steps ahead to compare)\n",
    "RET_THRESHOLD = 1e-5  # threshold for \"no-move\" vs up/down (relative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f3ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (3730870, 43)\n",
      "Columns: ['Unnamed: 0', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']  ... total 43\n",
      "Dropped 'Unnamed: 0'\n",
      "Using timestamp column: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ONGC\\AppData\\Local\\Temp\\ipykernel_27392\\4269268237.py:46: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['timestamp'] = pd.to_datetime(df[ts_col], utc=True, infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After parsing timestamp rows: (3730870, 43)\n",
      "0   2023-01-09 22:17:40+00:00\n",
      "1   2023-01-09 22:17:41+00:00\n",
      "2   2023-01-09 22:17:41+00:00\n",
      "3   2023-01-09 22:17:41+00:00\n",
      "4   2023-01-09 22:17:41+00:00\n",
      "Name: timestamp, dtype: datetime64[ns, UTC]\n",
      "Numeric columns count: 41\n",
      "Detected price-like cols (examples): ['0', '2', '4', '6', '8', '10', '12', '14', '16', '18']\n",
      "Detected size-like cols (examples): ['3', '5', '7', '9', '11', '13', '15', '17', '19', '21']\n",
      "Computed mid_price from price-like columns.\n",
      "Created imbalance using 3 5\n",
      "Final df shape: (3730870, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673302660926</td>\n",
       "      <td>2023-01-09 22:17:40</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>23.371</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.746</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1673302661177</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.232</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1673302661427</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.403</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1673302661678</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.874</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1673302661928</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.403</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                    1        2       3        4      5  \\\n",
       "0  1673302660926  2023-01-09 22:17:40  17181.6  23.371  17181.5  0.746   \n",
       "1  1673302661177  2023-01-09 22:17:41  17181.6  24.232  17181.5  0.694   \n",
       "2  1673302661427  2023-01-09 22:17:41  17181.6  24.403  17181.5  0.694   \n",
       "3  1673302661678  2023-01-09 22:17:41  17181.6  24.874  17181.5  0.694   \n",
       "4  1673302661928  2023-01-09 22:17:41  17181.6  24.403  17181.5  0.694   \n",
       "\n",
       "         6      7        8     9       10     11  \n",
       "0  17181.4  5.428  17181.2  0.89  17181.1  3.787  \n",
       "1  17181.4  5.428  17181.2  0.89  17181.1  3.787  \n",
       "2  17181.4  5.428  17181.2  0.89  17181.1  3.787  \n",
       "3  17181.4  5.428  17181.2  0.89  17181.1  3.776  \n",
       "4  17181.4  5.428  17181.2  0.89  17181.1  3.776  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RAW_CSV = \"E:/DL Project/data/lob.csv\"  \n",
    "df = pd.read_csv(RAW_CSV, low_memory=False)\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist()[:15], \" ... total\", len(df.columns))\n",
    "\n",
    "# 1) drop the extra index column if present\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    print(\"Dropped 'Unnamed: 0'\")\n",
    "\n",
    "# 2) detect timestamp column: prefer readable col '1' if present\n",
    "ts_col = None\n",
    "if 1 in df.columns and df[1].dtype == object:\n",
    "    ts_col = 1\n",
    "else:\n",
    "    # try to detect by parse-ability for object columns\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == object:\n",
    "            try:\n",
    "                _ = pd.to_datetime(df[c].iloc[0])\n",
    "                ts_col = c\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "    # fallback: numeric large-value column (unix ms)\n",
    "    if ts_col is None:\n",
    "        for c in df.columns:\n",
    "            if np.issubdtype(df[c].dtype, np.number):\n",
    "                val = float(df[c].iloc[0])\n",
    "                if 1e12 < val < 2e13:   # likely milliseconds\n",
    "                    ts_col = c\n",
    "                    break\n",
    "                if 1e9 < val < 2e10:    # likely seconds\n",
    "                    ts_col = c\n",
    "                    break\n",
    "\n",
    "if ts_col is None:\n",
    "    raise ValueError(\"Could not automatically detect timestamp column. Print df.columns and tell me the timestamp column name.\")\n",
    "print(\"Using timestamp column:\", ts_col)\n",
    "\n",
    "# 3) parse timestamps into datetime UTC\n",
    "if df[ts_col].dtype == object:\n",
    "    df['timestamp'] = pd.to_datetime(df[ts_col], utc=True, infer_datetime_format=True)\n",
    "else:\n",
    "    # numeric; decide ms vs s\n",
    "    example = float(df[ts_col].iloc[0])\n",
    "    if example > 1e12:\n",
    "        df['timestamp'] = pd.to_datetime(df[ts_col], unit='ms', utc=True)\n",
    "    else:\n",
    "        df['timestamp'] = pd.to_datetime(df[ts_col], unit='s', utc=True)\n",
    "\n",
    "# 4) drop rows with null timestamp and sort\n",
    "df = df.dropna(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)\n",
    "print(\"After parsing timestamp rows:\", df.shape)\n",
    "print(df['timestamp'].head())\n",
    "\n",
    "# 5) identify numeric feature columns (exclude timestamp + label if any)\n",
    "numeric_cols = [c for c in df.columns if c not in ('timestamp', ts_col) and np.issubdtype(df[c].dtype, np.number)]\n",
    "print(\"Numeric columns count:\", len(numeric_cols))\n",
    "\n",
    "# 6) heuristically separate price-like vs size-like by magnitude (BTC price ~ thousands, sizes tend to be small)\n",
    "col_stats = df[numeric_cols].agg(['mean','std','min','max']).transpose()\n",
    "col_stats['mean_abs'] = col_stats['mean'].abs()\n",
    "# price-like: mean_abs > 1000 (tweak if necessary). Size-like: mean_abs < 1000\n",
    "price_cols = col_stats[col_stats['mean_abs'] > 1000].index.tolist()\n",
    "size_cols  = col_stats[col_stats['mean_abs'] <= 1000].index.tolist()\n",
    "\n",
    "print(\"Detected price-like cols (examples):\", price_cols[:10])\n",
    "print(\"Detected size-like cols (examples):\", size_cols[:10])\n",
    "\n",
    "# 7) compute robust mid_price: (min_price + max_price)/2 among price-like columns in each row\n",
    "if len(price_cols) >= 2:\n",
    "    # min and max across the detected price columns per row\n",
    "    min_price = df[price_cols].min(axis=1)\n",
    "    max_price = df[price_cols].max(axis=1)\n",
    "    df['mid_price'] = (min_price + max_price) / 2.0\n",
    "    print(\"Computed mid_price from price-like columns.\")\n",
    "else:\n",
    "    # fallback: if not enough price columns detected, try a simple candidate: take first numeric col after timestamp\n",
    "    fallback = [c for c in df.columns if c not in ('timestamp', ts_col)]\n",
    "    fallback_numeric = [c for c in fallback if np.issubdtype(df[c].dtype, np.number)]\n",
    "    if len(fallback_numeric) >= 2:\n",
    "        df['mid_price'] = (df[fallback_numeric[0]] + df[fallback_numeric[1]]) / 2.0\n",
    "        print(\"Fallback mid_price from first two numeric columns:\", fallback_numeric[:2])\n",
    "    else:\n",
    "        raise ValueError(\"Cannot compute mid_price: not enough numeric columns detected.\")\n",
    "\n",
    "# 8) compute simple engineered features: log returns, spread if possible, imbalances if sizes present\n",
    "df['mid_logret'] = np.log(df['mid_price']).diff().fillna(0)\n",
    "df['mid_ret'] = df['mid_price'].pct_change().fillna(0)\n",
    "\n",
    "if len(size_cols) >= 2:\n",
    "    # create simple imbalance for first size pair (heuristic)\n",
    "    df['imbalance_1'] = (df[size_cols[0]] - df[size_cols[1]]) / (df[size_cols[0]] + df[size_cols[1]] + 1e-9)\n",
    "    print(\"Created imbalance using\", size_cols[0], size_cols[1])\n",
    "\n",
    "# 9) final housekeeping\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"Final df shape:\", df.shape)\n",
    "display(df.head().iloc[:, :12])   # show first 12 columns for quick check\n",
    "\n",
    "# Save or assign to CLEAN_CSV later in pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8471e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts (inc unlabeled -1):\n",
      " label_3\n",
      " 1    3730869\n",
      "-1          1\n",
      "Name: count, dtype: int64\n",
      "After dropping unlabeled tail: (3730869, 48)\n",
      "label_3\n",
      "1    1.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell A: 3-class labels\n",
    "HORIZON = 1            # steps ahead to compare\n",
    "RET_THRESHOLD = 1e-5   # relative change threshold (tweak later)\n",
    "\n",
    "def make_labels(df, horizon=HORIZON, threshold=RET_THRESHOLD):\n",
    "    mp = df['mid_price'].values\n",
    "    mp_future = np.roll(mp, -horizon)\n",
    "    valid = np.arange(len(df) - horizon)\n",
    "    ret = (mp_future - mp) / (mp + 1e-12)\n",
    "    labels = np.full(len(df), -1, dtype=int)\n",
    "    labels[valid] = np.where(ret[valid] > threshold, 2,\n",
    "                             np.where(ret[valid] < -threshold, 0, 1))\n",
    "    return labels\n",
    "\n",
    "df['label_3'] = make_labels(df, horizon=HORIZON, threshold=RET_THRESHOLD)\n",
    "print(\"Label counts (inc unlabeled -1):\\n\", pd.Series(df['label_3']).value_counts(dropna=False))\n",
    "# drop tail rows that cannot be labeled\n",
    "df = df[df['label_3'] != -1].reset_index(drop=True)\n",
    "print(\"After dropping unlabeled tail:\", df.shape)\n",
    "print(pd.Series(df['label_3']).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a99dad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return stats:\n",
      "count    3.730869e+06\n",
      "mean     1.498236e-10\n",
      "std      2.485995e-10\n",
      "min     -5.602555e-10\n",
      "25%      1.493159e-10\n",
      "50%      1.494114e-10\n",
      "75%      1.502931e-10\n",
      "max      5.585684e-08\n",
      "Name: mid_ret, dtype: float64\n",
      "abs(ret) > 1e-5: 0\n",
      "TH=1e-05: up=0, down=0, neutral=3730869\n",
      "TH=0.0001: up=0, down=0, neutral=3730869\n",
      "TH=0.0005: up=0, down=0, neutral=3730869\n",
      "TH=0.001: up=0, down=0, neutral=3730869\n"
     ]
    }
   ],
   "source": [
    "df['mid_ret'] = df['mid_price'].pct_change().fillna(0)\n",
    "\n",
    "print(\"Return stats:\")\n",
    "print(df['mid_ret'].describe())\n",
    "\n",
    "# how many rows with absolute return > 1e-5 ?\n",
    "print(\"abs(ret) > 1e-5:\", (df['mid_ret'].abs() > 1e-5).sum())\n",
    "\n",
    "# try slightly bigger threshold\n",
    "for th in [1e-5, 1e-4, 5e-4, 1e-3]:\n",
    "    c_up = (df['mid_ret'] > th).sum()\n",
    "    c_down = (df['mid_ret'] < -th).sum()\n",
    "    print(f\"TH={th}: up={c_up}, down={c_down}, neutral={len(df)-c_up-c_down}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4190350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns sample: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n",
      "Mapped columns (sample):\n",
      " unix_ts_col_key: 0\n",
      " human_ts_col_key: 1\n",
      " bid_price_cols: ['2', '4', '6', '8', '10', '12']\n",
      " bid_size_cols : ['3', '5', '7', '9', '11', '13']\n",
      " ask_price_cols: ['22', '24', '26', '28', '30', '32']\n",
      " ask_size_cols : ['23', '25', '27', '29', '31', '33']\n",
      "\n",
      "mid_price head:\n",
      "0    17181.65\n",
      "1    17181.65\n",
      "2    17181.65\n",
      "3    17181.65\n",
      "4    17181.65\n",
      "Name: mid_price, dtype: float64\n",
      "\n",
      "mid_price describe:\n",
      "count    3.730869e+06\n",
      "mean     1.986779e+04\n",
      "std      1.518495e+03\n",
      "min      1.711835e+04\n",
      "25%      1.822435e+04\n",
      "50%      2.078375e+04\n",
      "75%      2.104865e+04\n",
      "max      2.165985e+04\n",
      "Name: mid_price, dtype: float64\n",
      "\n",
      "mid_ret describe:\n",
      "count    3.730869e+06\n",
      "mean     5.910676e-08\n",
      "std      4.571530e-05\n",
      "min     -6.898424e-03\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.243061e-02\n",
      "Name: mid_ret, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673302660926</td>\n",
       "      <td>2023-01-09 22:17:40</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>23.371</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.746</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1673302661177</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.232</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1673302661427</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.403</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1673302661678</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.874</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1673302661928</td>\n",
       "      <td>2023-01-09 22:17:41</td>\n",
       "      <td>17181.6</td>\n",
       "      <td>24.403</td>\n",
       "      <td>17181.5</td>\n",
       "      <td>0.694</td>\n",
       "      <td>17181.4</td>\n",
       "      <td>5.428</td>\n",
       "      <td>17181.2</td>\n",
       "      <td>0.89</td>\n",
       "      <td>17181.1</td>\n",
       "      <td>3.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                    1        2       3        4      5  \\\n",
       "0  1673302660926  2023-01-09 22:17:40  17181.6  23.371  17181.5  0.746   \n",
       "1  1673302661177  2023-01-09 22:17:41  17181.6  24.232  17181.5  0.694   \n",
       "2  1673302661427  2023-01-09 22:17:41  17181.6  24.403  17181.5  0.694   \n",
       "3  1673302661678  2023-01-09 22:17:41  17181.6  24.874  17181.5  0.694   \n",
       "4  1673302661928  2023-01-09 22:17:41  17181.6  24.403  17181.5  0.694   \n",
       "\n",
       "         6      7        8     9       10     11  \n",
       "0  17181.4  5.428  17181.2  0.89  17181.1  3.787  \n",
       "1  17181.4  5.428  17181.2  0.89  17181.1  3.787  \n",
       "2  17181.4  5.428  17181.2  0.89  17181.1  3.787  \n",
       "3  17181.4  5.428  17181.2  0.89  17181.1  3.776  \n",
       "4  17181.4  5.428  17181.2  0.89  17181.1  3.776  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Robust Cell 1 replacement: works whether df.columns are ints or strings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# RAW_CSV already loaded earlier; but to be safe, reload a small head if df not present\n",
    "# (comment out reload if df is already in memory)\n",
    "# df = pd.read_csv(RAW_CSV, low_memory=False)\n",
    "\n",
    "print(\"Columns sample:\", df.columns.tolist()[:12])\n",
    "\n",
    "# helper to get column name that may be int or str\n",
    "def colname(x):\n",
    "    \"\"\"Return the actual column key in df for logical index x (0-based),\n",
    "       handling column labels that are ints or their string equivalents.\"\"\"\n",
    "    # possible forms\n",
    "    if x in df.columns:\n",
    "        return x\n",
    "    s = str(x)\n",
    "    if s in df.columns:\n",
    "        return s\n",
    "    # sometimes pandas read as 'Unnamed: 0' removed earlier; try integer lookup by position\n",
    "    try:\n",
    "        # return label at position x (0-based)\n",
    "        return df.columns[x]\n",
    "    except Exception:\n",
    "        raise KeyError(f\"Could not find column for index {x}. Available cols: {df.columns[:12].tolist()}\")\n",
    "\n",
    "# map logical positions -> actual keys\n",
    "unix_ts_col_key = colname(0)\n",
    "human_ts_col_key = colname(1)\n",
    "\n",
    "# build lists for bid/ask columns (logical positions) and map them to real keys\n",
    "bid_price_positions = list(range(2, 22, 2))   # logical indices 2,4,...20\n",
    "bid_size_positions  = list(range(3, 23, 2))   # 3,5,...21\n",
    "ask_price_positions = list(range(22, 42, 2))  # 22,24,...40\n",
    "ask_size_positions  = list(range(23, 43, 2))  # 23,25,...41\n",
    "\n",
    "# convert positions to actual df column keys\n",
    "bid_price_cols = [colname(p) for p in bid_price_positions]\n",
    "bid_size_cols  = [colname(p) for p in bid_size_positions]\n",
    "ask_price_cols = [colname(p) for p in ask_price_positions]\n",
    "ask_size_cols  = [colname(p) for p in ask_size_positions]\n",
    "\n",
    "print(\"Mapped columns (sample):\")\n",
    "print(\" unix_ts_col_key:\", unix_ts_col_key)\n",
    "print(\" human_ts_col_key:\", human_ts_col_key)\n",
    "print(\" bid_price_cols:\", bid_price_cols[:6])\n",
    "print(\" bid_size_cols :\", bid_size_cols[:6])\n",
    "print(\" ask_price_cols:\", ask_price_cols[:6])\n",
    "print(\" ask_size_cols :\", ask_size_cols[:6])\n",
    "\n",
    "# parse timestamp: dataset uses microseconds -> unit='us'\n",
    "try:\n",
    "    df['timestamp'] = pd.to_datetime(df[unix_ts_col_key], unit='us', utc=True)\n",
    "except Exception as e:\n",
    "    # fallback: if human-readable col exists, use that\n",
    "    print(\"Failed parsing unix microseconds on column\", unix_ts_col_key, \"->\", e)\n",
    "    try:\n",
    "        df['timestamp'] = pd.to_datetime(df[human_ts_col_key], utc=True, infer_datetime_format=True)\n",
    "    except Exception as e2:\n",
    "        raise RuntimeError(\"Could not parse timestamp from either column. Errors:\\n1) {}\\n2) {}\".format(e, e2))\n",
    "\n",
    "# sort by timestamp\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# ensure numeric types for price columns (coerce if necessary)\n",
    "for c in bid_price_cols + ask_price_cols + bid_size_cols + ask_size_cols:\n",
    "    # some columns might be read as strings due to commas etc. coerce to float\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# drop rows with NaNs in best bid/ask after coercion\n",
    "df = df.dropna(subset=[bid_price_cols[0], ask_price_cols[0]]).reset_index(drop=True)\n",
    "\n",
    "# compute mid-price from best bid & ask (level 1)\n",
    "df['mid_price'] = (df[ask_price_cols[0]] + df[bid_price_cols[0]]) / 2.0\n",
    "df['mid_ret'] = df['mid_price'].pct_change().fillna(0)\n",
    "\n",
    "# quick checks\n",
    "print(\"\\nmid_price head:\")\n",
    "print(df['mid_price'].head(5))\n",
    "print(\"\\nmid_price describe:\")\n",
    "print(df['mid_price'].describe())\n",
    "print(\"\\nmid_ret describe:\")\n",
    "print(df['mid_ret'].describe())\n",
    "\n",
    "# show first few columns for visual sanity\n",
    "display(df.iloc[:5, :12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c94ba0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using feature columns (count): 40\n",
      "['2', '4', '6', '8', '10', '12', '14', '16', '18', '20', '22', '24', '26', '28', '30', '32', '34', '36', '38', '40', '3', '5', '7', '9', '11', '13', '15', '17', '19', '21', '23', '25', '27', '29', '31', '33', '35', '37', '39', '41']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "# recommended feature order: [bid_px1, bid_px2, ..., bid_px10, ask_px1, ask_px2, ..., ask_px10,\n",
    "#                             bid_vol1, bid_vol2, ..., bid_vol10, ask_vol1, ... ask_vol10]\n",
    "feature_cols = []\n",
    "\n",
    "# append bid prices then ask prices (10 each)\n",
    "feature_cols += bid_price_cols\n",
    "feature_cols += ask_price_cols\n",
    "# then bid sizes then ask sizes\n",
    "feature_cols += bid_size_cols\n",
    "feature_cols += ask_size_cols\n",
    "\n",
    "# Keep only first 40 if you want NF=40 (but here there are exactly 40)\n",
    "feature_cols = feature_cols[:40]\n",
    "print(\"Using feature columns (count):\", len(feature_cols))\n",
    "print(feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86fef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts incl -1: label_3\n",
      " 1    2395317\n",
      " 2     670478\n",
      " 0     665054\n",
      "-1         20\n",
      "Name: count, dtype: int64\n",
      "Final label distribution:\n",
      "label_3\n",
      "1    0.642030\n",
      "2    0.179712\n",
      "0    0.178258\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Create labels\n",
    "HORIZON = 20\n",
    "RET_THRESHOLD = 1e-4  # 0.01%\n",
    "\n",
    "def make_labels(df, horizon=HORIZON, threshold=RET_THRESHOLD):\n",
    "    mp = df['mid_price'].values\n",
    "    mp_future = np.roll(mp, -horizon)\n",
    "    labels = np.full(len(df), -1, dtype=int)\n",
    "    \n",
    "    ret = (mp_future - mp) / (mp + 1e-12)\n",
    "    valid = np.arange(len(df) - horizon)\n",
    "\n",
    "    labels[valid] = np.where(\n",
    "        ret[valid] > threshold, 2,\n",
    "        np.where(ret[valid] < -threshold, 0, 1)\n",
    "    )\n",
    "    return labels\n",
    "\n",
    "df['label_3'] = make_labels(df, HORIZON, RET_THRESHOLD)\n",
    "print(\"Counts incl -1:\", pd.Series(df['label_3']).value_counts())\n",
    "\n",
    "# Drop unlabeled tail\n",
    "df = df[df['label_3'] != -1].reset_index(drop=True)\n",
    "print(\"Final label distribution:\")\n",
    "print(pd.Series(df['label_3']).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59da7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this once to set params\n",
    "WINDOW_SIZE = 300    # use 300 unless you want smaller for experiments\n",
    "BATCH_SIZE = 64\n",
    "SAMPLE_FOR_SCALER = 2000   # number of windows to sample from train for scaler\n",
    "HORIZON = 20\n",
    "RET_THRESHOLD = 1e-4\n",
    "EPOCHS = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0c117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (train/val/test): 2611594 559627 559628\n",
      "Train label counts (head): label_3\n",
      "1    0.640456\n",
      "2    0.180592\n",
      "0    0.178952\n",
      "Name: proportion, dtype: float64\n",
      "Val label counts (head): label_3\n",
      "1    0.573298\n",
      "0    0.214729\n",
      "2    0.211973\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Time-based split using quantiles (no leakage)\n",
    "train_q = 0.70\n",
    "val_q = 0.85\n",
    "\n",
    "train_cut = df['timestamp'].quantile(train_q)\n",
    "val_cut   = df['timestamp'].quantile(val_q)\n",
    "\n",
    "df_train = df[df['timestamp'] <= train_cut].reset_index(drop=True)\n",
    "df_val   = df[(df['timestamp'] > train_cut) & (df['timestamp'] <= val_cut)].reset_index(drop=True)\n",
    "df_test  = df[df['timestamp'] > val_cut].reset_index(drop=True)\n",
    "\n",
    "print(\"Rows (train/val/test):\", len(df_train), len(df_val), len(df_test))\n",
    "# quick label checks (after window offset)\n",
    "print(\"Train label counts (head):\", pd.Series(df_train['label_3']).value_counts(normalize=True))\n",
    "print(\"Val label counts (head):\", pd.Series(df_val['label_3']).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2987ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_windows shape: (2000, 300, 40)\n",
      "Scaler fitted; mean shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "FEATURE_COLS = bid_price_cols + bid_size_cols + ask_price_cols + ask_size_cols\n",
    "FEATURE_COLS = FEATURE_COLS[:40]   # ensure NF=40\n",
    "\n",
    "def df_windows_generator_sample(df_slice, feature_cols, window_size=WINDOW_SIZE):\n",
    "    n = len(df_slice)\n",
    "    for end in range(window_size, n):\n",
    "        start = end - window_size\n",
    "        X = df_slice.iloc[start:end][feature_cols].values.astype(np.float32)\n",
    "        yield X\n",
    "\n",
    "# sample windows\n",
    "sample_windows = []\n",
    "gen = df_windows_generator_sample(df_train, FEATURE_COLS, window_size=WINDOW_SIZE)\n",
    "for i, x in enumerate(gen):\n",
    "    sample_windows.append(x)\n",
    "    if i >= SAMPLE_FOR_SCALER - 1:\n",
    "        break\n",
    "\n",
    "sample_windows = np.stack(sample_windows)  # shape: (SAMPLE_FOR_SCALER, W, F)\n",
    "print(\"sample_windows shape:\", sample_windows.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(sample_windows.reshape(-1, sample_windows.shape[-1]))   # fit on time-steps across windows\n",
    "\n",
    "# save scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, \"scaler_deeplob.save\")\n",
    "print(\"Scaler fitted; mean shape:\", scaler.mean_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a424543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights vector: [1.8624867 0.5204952 1.845577 ]\n",
      "x batch shape: (64, 300, 40, 1)  y shape: (64, 3)  w shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "SHUFFLE_BUFFER = 8192\n",
    "NF = len(FEATURE_COLS)  # 40\n",
    "\n",
    "# dataset of indices (end positions)\n",
    "def make_index_ds(df_slice, window_size=WINDOW_SIZE):\n",
    "    n = len(df_slice)\n",
    "    if n <= window_size:\n",
    "        return None\n",
    "    indices = np.arange(window_size, n, dtype=np.int32)\n",
    "    return tf.data.Dataset.from_tensor_slices(indices)\n",
    "\n",
    "# fetch window in python (used by tf.numpy_function)\n",
    "def fetch_window_by_index(df_slice, feature_cols, idx):\n",
    "    i = int(idx)\n",
    "    start = i - WINDOW_SIZE\n",
    "    win = df_slice.iloc[start:i][feature_cols].values.astype(np.float32)\n",
    "    lab = int(df_slice.iloc[i]['label_3'])\n",
    "    return win, np.int32(lab)\n",
    "\n",
    "# map index -> (x,y)\n",
    "def map_index_to_window(df_slice):\n",
    "    def _map(idx):\n",
    "        x, y = tf.numpy_function(\n",
    "            func=lambda k: fetch_window_by_index(df_slice, FEATURE_COLS, k),\n",
    "            inp=[idx],\n",
    "            Tout=[tf.float32, tf.int32]\n",
    "        )\n",
    "        x.set_shape((WINDOW_SIZE, NF))\n",
    "        y.set_shape(())\n",
    "        return x, y\n",
    "    return _map\n",
    "\n",
    "def make_tf_dataset_from_df_safe(df_slice, shuffle=False):\n",
    "    ds_idx = make_index_ds(df_slice, WINDOW_SIZE)\n",
    "    if ds_idx is None:\n",
    "        raise ValueError(\"df_slice too small for window_size\")\n",
    "    if shuffle:\n",
    "        ds_idx = ds_idx.shuffle(SHUFFLE_BUFFER)\n",
    "    ds = ds_idx.map(map_index_to_window(df_slice), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# build raw ds\n",
    "raw_train_ds = make_tf_dataset_from_df_safe(df_train, shuffle=True)\n",
    "raw_val_ds   = make_tf_dataset_from_df_safe(df_val, shuffle=False)\n",
    "raw_test_ds  = make_tf_dataset_from_df_safe(df_test, shuffle=False)\n",
    "\n",
    "# prepare scaler constants for TF\n",
    "scaler_mean = tf.constant(scaler.mean_, dtype=tf.float32)   # shape (NF,)\n",
    "scaler_scale = tf.constant(scaler.scale_, dtype=tf.float32)\n",
    "\n",
    "# compute class weights (from training labels actually used in windows)\n",
    "train_labels_for_windows = df_train['label_3'].values[WINDOW_SIZE:]   # labels corresponding to windows\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "cw = compute_class_weight('balanced', classes=np.unique(train_labels_for_windows), y=train_labels_for_windows)\n",
    "# cw maps to classes sorted order — build vector weight_by_label where index=label\n",
    "# labels are 0,1,2\n",
    "weight_by_label = np.ones(3, dtype=np.float32)\n",
    "unique_classes = np.unique(train_labels_for_windows)\n",
    "for i, lab in enumerate(unique_classes):\n",
    "    weight_by_label[int(lab)] = float(cw[i])\n",
    "print(\"Class weights vector:\", weight_by_label)\n",
    "weight_by_label_tf = tf.constant(weight_by_label, dtype=tf.float32)\n",
    "\n",
    "# mapping functions: scale, add channel, one-hot labels, sample-weight\n",
    "def scale_and_prepare(x, y):\n",
    "    # x shape: (batch, W, NF)\n",
    "    x = (x - scaler_mean) / scaler_scale   # broadcasts over W\n",
    "    x = tf.expand_dims(x, axis=-1)         # (batch, W, NF, 1)\n",
    "    y_onehot = tf.one_hot(y, depth=3)\n",
    "    sample_w = tf.gather(weight_by_label_tf, y)  # yields shape (batch,)\n",
    "    return x, y_onehot, sample_w\n",
    "\n",
    "# build final datasets\n",
    "train_ds_model = raw_train_ds.map(lambda x,y: scale_and_prepare(x,y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds_model   = raw_val_ds.map(lambda x,y: scale_and_prepare(x,y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds_model  = raw_test_ds.map(lambda x,y: scale_and_prepare(x,y), num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# quick sanity check: inspect one batch\n",
    "for xb, yb, wb in train_ds_model.take(1):\n",
    "    print(\"x batch shape:\", xb.shape, \" y shape:\", yb.shape, \" w shape:\", wb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a7d8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ leaky_re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ leaky_re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ leaky_re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ leaky_re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ leaky_re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ leaky_re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │ leaky_re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ leaky_re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">508,160</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │         \u001b[38;5;34m96\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │        \u001b[38;5;34m128\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │      \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │        \u001b[38;5;34m128\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │      \u001b[38;5;34m4,128\u001b[0m │ leaky_re_lu_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │        \u001b[38;5;34m128\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m20\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │      \u001b[38;5;34m2,080\u001b[0m │ leaky_re_lu_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │        \u001b[38;5;34m128\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │      \u001b[38;5;34m2,112\u001b[0m │ leaky_re_lu_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │      \u001b[38;5;34m2,112\u001b[0m │ leaky_re_lu_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │        \u001b[38;5;34m256\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │        \u001b[38;5;34m256\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │     \u001b[38;5;34m12,352\u001b[0m │ leaky_re_lu_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │     \u001b[38;5;34m20,544\u001b[0m │ leaky_re_lu_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │      \u001b[38;5;34m2,112\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │        \u001b[38;5;34m256\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │        \u001b[38;5;34m256\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │        \u001b[38;5;34m256\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m10\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m192\u001b[0m)              │            │ leaky_re_lu_16[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ leaky_re_lu_17[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m1920\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m1920\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │    \u001b[38;5;34m508,160\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">559,811</span> (2.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m559,811\u001b[0m (2.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">558,915</span> (2.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m558,915\u001b[0m (2.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fixed DeepLOB model: correct reshape (flatten width * channels per time step)\n",
    "from tensorflow.keras import layers, regularizers, Model, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        eps = 1e-8\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        cross = - y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
    "        return tf.reduce_mean(weight * cross)\n",
    "    return loss\n",
    "\n",
    "def create_deeplob_reg(T=WINDOW_SIZE, NF=NF, number_of_lstm=64, l2=1e-4, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Corrected reshape: after conv block tensor shape is (batch, T, W, C).\n",
    "    We want a sequence of length T where each time-step has features W*C.\n",
    "    \"\"\"\n",
    "    input_lmd = Input(shape=(T, NF, 1))\n",
    "    kreg = regularizers.l2(l2)\n",
    "\n",
    "    # initial conv stack\n",
    "    x = layers.Conv2D(32, (1,2), strides=(1,2), kernel_regularizer=kreg)(input_lmd)\n",
    "    x = layers.BatchNormalization()(x); x = layers.LeakyReLU(0.01)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, (4,1), padding='same', kernel_regularizer=kreg)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.LeakyReLU(0.01)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, (4,1), padding='same', kernel_regularizer=kreg)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.LeakyReLU(0.01)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, (1,2), strides=(1,2), kernel_regularizer=kreg)(x)\n",
    "    x = layers.BatchNormalization()(x); x = layers.LeakyReLU(0.01)(x)\n",
    "\n",
    "    # inception-like block\n",
    "    b1 = layers.Conv2D(64, (1,1), padding='same', kernel_regularizer=kreg)(x)\n",
    "    b1 = layers.BatchNormalization()(b1); b1 = layers.LeakyReLU(0.01)(b1)\n",
    "    b1 = layers.Conv2D(64, (3,1), padding='same', kernel_regularizer=kreg)(b1)\n",
    "    b1 = layers.BatchNormalization()(b1); b1 = layers.LeakyReLU(0.01)(b1)\n",
    "\n",
    "    b2 = layers.Conv2D(64, (1,1), padding='same', kernel_regularizer=kreg)(x)\n",
    "    b2 = layers.BatchNormalization()(b2); b2 = layers.LeakyReLU(0.01)(b2)\n",
    "    b2 = layers.Conv2D(64, (5,1), padding='same', kernel_regularizer=kreg)(b2)\n",
    "    b2 = layers.BatchNormalization()(b2); b2 = layers.LeakyReLU(0.01)(b2)\n",
    "\n",
    "    b3 = layers.MaxPooling2D((3,1), strides=(1,1), padding='same')(x)\n",
    "    b3 = layers.Conv2D(64, (1,1), padding='same', kernel_regularizer=kreg)(b3)\n",
    "    b3 = layers.BatchNormalization()(b3); b3 = layers.LeakyReLU(0.01)(b3)\n",
    "\n",
    "    x = layers.concatenate([b1, b2, b3], axis=3)  # shape: (batch, T, W, C)\n",
    "\n",
    "    # correct reshape: flatten width * channels per time-step\n",
    "    # x.shape -> (batch, seq_len=T, width=W, channels=C)\n",
    "    seq_len = int(x.shape[1])   # T\n",
    "    width   = int(x.shape[2])   # W\n",
    "    channels = int(x.shape[3])  # C\n",
    "    feat_dim = width * channels\n",
    "    x = layers.Reshape((seq_len, feat_dim))(x)    # -> (batch, T, W*C)\n",
    "\n",
    "    # recurrent block\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.LSTM(number_of_lstm, kernel_regularizer=kreg, recurrent_regularizer=kreg)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    out = layers.Dense(3, activation='softmax', kernel_regularizer=kreg)(x)\n",
    "    return Model(inputs=input_lmd, outputs=out)\n",
    "\n",
    "# Recreate and compile model\n",
    "model = create_deeplob_reg(T=WINDOW_SIZE, NF=NF, number_of_lstm=64)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt, loss=focal_loss(gamma=2., alpha=.25), metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b931798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688ms/step - accuracy: 0.8903 - loss: 0.0709\n",
      "Epoch 1: val_loss improved from None to 0.09220, saving model to best_deeplob_quick.keras\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1082s\u001b[0m 721ms/step - accuracy: 0.9007 - loss: 0.0566 - val_accuracy: 0.5423 - val_loss: 0.0922 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - accuracy: 0.9563 - loss: 0.0280\n",
      "Epoch 2: val_loss improved from 0.09220 to 0.06812, saving model to best_deeplob_quick.keras\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1106s\u001b[0m 737ms/step - accuracy: 0.9471 - loss: 0.0246 - val_accuracy: 0.5423 - val_loss: 0.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700ms/step - accuracy: 0.8578 - loss: 0.0236\n",
      "Epoch 3: val_loss improved from 0.06812 to 0.05419, saving model to best_deeplob_quick.keras\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1099s\u001b[0m 733ms/step - accuracy: 0.7959 - loss: 0.0271 - val_accuracy: 0.5423 - val_loss: 0.0542 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701ms/step - accuracy: 0.8107 - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.05419 to 0.05162, saving model to best_deeplob_quick.keras\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1100s\u001b[0m 733ms/step - accuracy: 0.8544 - loss: 0.0190 - val_accuracy: 0.5423 - val_loss: 0.0516 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m   7/1500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:02\u001b[0m 685ms/step - accuracy: 0.8735 - loss: 0.0155"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m      3\u001b[39m VAL_STEPS = \u001b[32m300\u001b[39m          \u001b[38;5;66;03m# evaluate on 300 val batches\u001b[39;00m\n\u001b[32m      6\u001b[39m callbacks = [\n\u001b[32m      7\u001b[39m     tf.keras.callbacks.ModelCheckpoint(\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbest_deeplob_quick.keras\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     )\n\u001b[32m     31\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFAST_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVAL_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     42\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1550\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1560\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1561\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1562\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1566\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1567\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\DL Project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# QUICK RUN FOR PROJECT REVIEW - FAST AND SHOWS IMPROVEMENT\n",
    "FAST_STEPS = 1500        # trains on 1500 batches only (fast)\n",
    "VAL_STEPS = 300          # evaluate on 300 val batches\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_deeplob_quick.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs/deeplob_quick',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds_model,\n",
    "    validation_data=val_ds_model,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=FAST_STEPS,\n",
    "    validation_steps=VAL_STEPS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
